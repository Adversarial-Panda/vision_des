{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e340fa8c-f6aa-4f22-8149-5bee0861ec68",
   "metadata": {},
   "source": [
    "## CIFAR-10 under CW attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8dd632c-c01c-43c6-b157-e1f87c87d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import time \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from medmnist import INFO\n",
    "import numpy as np\n",
    "import faiss\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.nn.functional import softmax, cosine_similarity\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import clip\n",
    "import os \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "278793fe-dcf6-4ab0-b377-c0557a7d9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = 'cuda:0' \n",
    "\n",
    "device = torch.device(device_name if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da3cf88-1834-40e5-81ff-6c495c75ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import archetecture of models \n",
    "\n",
    "from trained_models_cifar10.models.vgg_models import * \n",
    "from trained_models_cifar10.models.resnet_models import * \n",
    "from trained_models_cifar10.models.densenet_models import * \n",
    "from trained_models_cifar10.models.mobilenetv2_cifar10 import * \n",
    "from trained_models_cifar10.models.googlenet_cifar10 import * \n",
    "from trained_models_cifar10.models.xception_cifar10 import * \n",
    "from trained_models_cifar10.models.inceptionv3_cifar10 import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456ef8d1-0ee4-4921-9729-cf5bf0c89886",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the archetecture of model from models.vgg_models \n",
    "vgg19_model = VGG('VGG19')\n",
    "resnet50_model = ResNet50() \n",
    "densenet169_model = DenseNet169() \n",
    "mobilenetV2_model = MobileNetV2() \n",
    "googlenet_model = GoogLeNet()  \n",
    "xception_model = xception()  \n",
    "inceptionv3_model = inceptionv3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc1add9-d1f2-4c6b-a78e-527a7d808d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models_directory = \"trained_models_cifar10/\" \n",
    "\n",
    "vgg_19_model_file_name = \"vgg19_cifar10_lr01.pth\" \n",
    "resnet50_model_file_name = \"resnet50_cifar10_lr01.pth\" \n",
    "densenet169_model_file_name = \"densenet169_cifar10_lr01.pth\" \n",
    "mobilenetV2_model_file_name = \"mobilenetv2_cifar10_lr01.pth\" \n",
    "googlenet_model_file_name = \"googlenet_cifar_lr01.pth\" \n",
    "xception_model_file_name = \"xception_cifar10_lr01.pth\" \n",
    "inceptionv3_model_file_name = \"inceptionv3_cifar10_lr01.pth\"\n",
    "\n",
    "vgg19_path = os.path.join(trained_models_directory, vgg_19_model_file_name) \n",
    "resnet50_path = os.path.join(trained_models_directory, resnet50_model_file_name) \n",
    "densenet169_path = os.path.join(trained_models_directory, densenet169_model_file_name) \n",
    "mobilenetV2_path = os.path.join(trained_models_directory, mobilenetV2_model_file_name) \n",
    "googlenet_path = os.path.join(trained_models_directory, googlenet_model_file_name) \n",
    "xception_path = os.path.join(trained_models_directory, xception_model_file_name) \n",
    "inceptionv3_path = os.path.join(trained_models_directory, inceptionv3_model_file_name) \n",
    "\n",
    "## load the model \n",
    "vgg19_model.load_state_dict(torch.load(vgg19_path, map_location=device_name)['net'])\n",
    "resnet50_model.load_state_dict(torch.load(resnet50_path, map_location=device_name)['net'])\n",
    "densenet169_model.load_state_dict(torch.load(densenet169_path, map_location=device_name)['net'])\n",
    "mobilenetV2_model.load_state_dict(torch.load(mobilenetV2_path, map_location=device_name)['net'])\n",
    "googlenet_model.load_state_dict(torch.load(googlenet_path, map_location=device_name)['net'])\n",
    "xception_model.load_state_dict(torch.load(xception_path, map_location=device_name)['net'])\n",
    "inceptionv3_model.load_state_dict(torch.load(inceptionv3_path, map_location=device_name)['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb75983d-abfe-49c0-917c-c6fc17fd5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_pool = [\n",
    "                # vgg19_model.eval(), \n",
    "                resnet50_model.eval(), \n",
    "                densenet169_model.eval(), \n",
    "                mobilenetV2_model.eval(), \n",
    "                googlenet_model.eval(), \n",
    "                xception_model.eval(), \n",
    "                inceptionv3_model.eval()\n",
    "               ]\n",
    "\n",
    "\n",
    "model_names = [\n",
    "    # \"VGG19\",\n",
    "    \"ResNet50\",\n",
    "    \"DenseNet169\",\n",
    "    \"MobileNetV2\",\n",
    "    \"GoogleNet\", \n",
    "    \"Xception\", \n",
    "    \"InceptionV3\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1988c-b33f-4f9e-ab3d-1cf3362f3f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "403f56ce-d6d5-49e0-ba31-79b452c71cbe",
   "metadata": {},
   "source": [
    "### Dataset Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99958ae6-4e15-405e-91d3-50cbdaa25b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 8000\n",
      "Test samples: 2000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load the full CIFAR10 test set (10,000 samples)\n",
    "full_testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Calculate split sizes\n",
    "val_size = int(0.80 * len(full_testset))  # 7000\n",
    "test_size = len(full_testset) - val_size  # 3000\n",
    "\n",
    "# Randomly split into validation and test subsets\n",
    "val_set, test_set = random_split(\n",
    "    full_testset, [val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(56)\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "valloader = DataLoader(val_set, batch_size=100, shuffle=False, num_workers=2)\n",
    "testloader = DataLoader(test_set, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Validation samples: {len(val_set)}\")\n",
    "print(f\"Test samples: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d39c4-5747-46fb-89d3-24369c43bec7",
   "metadata": {},
   "source": [
    "## Base Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de9a88b-0d67-4a99-bb93-e8fb944c1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_test_and_roc(test_img, roc_imgs, local_labels, class_names=None):\n",
    "    def denormalize(img_tensor, mean, std):\n",
    "        mean = torch.tensor(mean).view(-1, 1, 1).to(img_tensor.device)\n",
    "        std = torch.tensor(std).view(-1, 1, 1).to(img_tensor.device)\n",
    "        return img_tensor * std + mean\n",
    "\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std  = [0.229, 0.224, 0.225] \n",
    "\n",
    "    k = roc_imgs.size(0)\n",
    "    ncols = min(k, 5)\n",
    "    nrows = 1 + (k + ncols - 1) // ncols  # one row for test image + RoC images\n",
    "    \n",
    "    plt.figure(figsize=(3 * ncols, 3 * nrows))\n",
    "    \n",
    "    # Plot test image\n",
    "    plt.subplot(nrows, ncols, 1)\n",
    "    denorm_img = denormalize(test_img, mean, std).clamp(0, 1)\n",
    "    img_np = TF.to_pil_image(denorm_img.cpu())\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(\"Test Image\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # Plot RoC images\n",
    "    for i in range(k):\n",
    "        plt.subplot(nrows, ncols, i + 2)\n",
    "        denorm_img = denormalize(roc_imgs[i], mean, std).clamp(0, 1)\n",
    "        img_np = TF.to_pil_image(denorm_img.cpu())\n",
    "        label = local_labels[i]\n",
    "        if class_names:\n",
    "            label = class_names[label]\n",
    "        plt.imshow(img_np)\n",
    "        plt.title(f\"RoC #{i+1}\\nLabel: {label}\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1152dba2-b8cf-447c-a9d4-6a5d0459761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_linear_layer(model):\n",
    "    \"\"\"\n",
    "    Try to find the last Linear layer in the model,\n",
    "    using common attribute names and fallback to scanning modules.\n",
    "    \"\"\"\n",
    "    name = model.__class__.__name__.lower()\n",
    "\n",
    "    # Common last layer attribute names to try (ViT, EfficientNet, etc)\n",
    "    candidate_attrs = ['head', 'heads', 'classifier', 'fc', 'mlp_head']\n",
    "\n",
    "    for attr in candidate_attrs:\n",
    "        if hasattr(model, attr):\n",
    "            layer = getattr(model, attr)\n",
    "            # If it's directly a Linear layer\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                return layer\n",
    "            # If Sequential or Module, find last Linear inside it\n",
    "            if isinstance(layer, nn.Sequential) or isinstance(layer, nn.Module):\n",
    "                # Find last Linear inside this attribute recursively\n",
    "                last_linear = None\n",
    "                for child in reversed(list(layer.modules())):\n",
    "                    if isinstance(child, nn.Linear):\n",
    "                        last_linear = child\n",
    "                        break\n",
    "                if last_linear is not None:\n",
    "                    return last_linear\n",
    "\n",
    "    # Fallback: scan all modules and pick the last Linear\n",
    "    last_linear = None\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            last_linear = m\n",
    "    if last_linear is not None:\n",
    "        return last_linear\n",
    "\n",
    "    raise RuntimeError(\"No Linear layer found in model\")\n",
    "\n",
    "\n",
    "def get_features_before_last_linear(model, x):\n",
    "    features = {}\n",
    "\n",
    "    def find_last_linear(module):\n",
    "        last_linear = None\n",
    "        for m in module.modules():\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                last_linear = m\n",
    "        return last_linear\n",
    "\n",
    "    last_linear = find_last_linear(model)\n",
    "    if last_linear is None:\n",
    "        raise RuntimeError(\"No Linear layer found in model\")\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        features['feat'] = input[0].detach()\n",
    "\n",
    "    handle = last_linear.register_forward_hook(hook)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(x)\n",
    "\n",
    "    handle.remove()\n",
    "\n",
    "    if 'feat' not in features:\n",
    "        raise RuntimeError(\"Failed to capture features from last linear layer\")\n",
    "\n",
    "    return features['feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5af5fd3-948c-4a60-83e8-4921cb4fd178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire_check(local_labels, preds, per_class_min=1):\n",
    "    local_labels = np.asarray(local_labels)\n",
    "\n",
    "    # If preds are logits/probs, convert to labels\n",
    "    preds = np.asarray(preds)\n",
    "    if preds.ndim > 1:\n",
    "        preds = preds.argmax(axis=1)\n",
    "\n",
    "    # Classes present in the RoC (unique, not repeated)\n",
    "    classes_in_roc = np.unique(local_labels)\n",
    "\n",
    "    # Check: for each class c in RoC, there is at least `per_class_min` correct prediction\n",
    "    missing = []\n",
    "    for c in classes_in_roc:\n",
    "        mask = (local_labels == c)\n",
    "        n_correct = int(np.sum(preds[mask] == c))\n",
    "        if n_correct < per_class_min:\n",
    "            missing.append((int(c), n_correct))  # track which class is short\n",
    "\n",
    "    fire_ok = (len(missing) == 0)\n",
    "    return fire_ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e419cc0-d10f-46e2-aa8c-42b4173ca370",
   "metadata": {},
   "source": [
    "## VisionDES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e601fbc7-41ed-4826-aeac-c6068b7bc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VisionDES: \n",
    "    def __init__(self, dsel_dataset, pool): \n",
    "        self.dsel_dataset = dsel_dataset\n",
    "        self.dsel_loader = DataLoader(dsel_dataset, batch_size=32, shuffle=False) \n",
    "        self.dino_model = timm.create_model('vit_base_patch16_224.dino', pretrained=True).to(device)\n",
    "        self.dino_model.eval()  \n",
    "        self.pool = pool \n",
    "\n",
    "        self.suspected_model_votes = [] \n",
    "        \n",
    "        \n",
    "    def dino_embedder(self, images):\n",
    "        if images.shape[1] == 1:\n",
    "            images = images.repeat(1, 3, 1, 1)\n",
    "\n",
    "        images = F.interpolate(images, size=(224, 224), mode=\"bilinear\", align_corners=False) \n",
    "        return self.dino_model.forward_features(images)\n",
    "\n",
    "\n",
    "    def fit(self): \n",
    "        dsel_embeddings = []\n",
    "        dsel_labels = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(self.dsel_loader):\n",
    "                imgs = imgs.to(device)\n",
    "                embs = self.dino_embedder(imgs).cpu()  \n",
    "                dsel_embeddings.append(embs)\n",
    "                dsel_labels.append(labels)\n",
    "    \n",
    "        # Keep as tensor\n",
    "        dsel_embeddings_tensor = torch.cat(dsel_embeddings).detach().cpu()  \n",
    "        cls_tensor = dsel_embeddings_tensor[:, 0, :]  \n",
    "    \n",
    "        # Convert to NumPy\n",
    "        cls_embeddings = np.ascontiguousarray(cls_tensor.numpy(), dtype='float32')\n",
    "        self.dsel_embeddings = cls_embeddings\n",
    "        self.dsel_labels = torch.cat(dsel_labels).numpy()\n",
    "    \n",
    "        # Build FAISS index\n",
    "        embedding_dim = cls_embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(embedding_dim)\n",
    "        self.index.add(cls_embeddings)\n",
    "\n",
    "    \n",
    "    def get_output_size(self, model):\n",
    "        \"\"\"\n",
    "        Returns the output size (number of classes) from various model architectures.\n",
    "        \"\"\"\n",
    "        if hasattr(model, 'fc'):\n",
    "            return model.fc.out_features\n",
    "        elif hasattr(model, 'classifier'):\n",
    "            if isinstance(model.classifier, nn.Sequential):\n",
    "                return model.classifier[-1].out_features\n",
    "            else:\n",
    "                return model.classifier.out_features\n",
    "        elif hasattr(model, 'heads'):  # ViT / DINO from torchvision\n",
    "            return model.heads.head.out_features\n",
    "        elif hasattr(model, 'head'):  # ViT/Swin from timm\n",
    "            return model.head.out_features\n",
    "        else:\n",
    "            raise AttributeError(\"Cannot determine output size of the model.\")\n",
    "\n",
    "\n",
    "    def predict_weighted_robust(self, test_img, k=7, return_logits=False, explain=False, top=False, n=3, use_fire=False, per_class_min=1, \n",
    "                                use_sim=False, sim_threshold=0, alpha=0.6, knorae=False):\n",
    "        # Step 1: Get DINO CLS embedding for the test image\n",
    "        img_for_dino = test_img.unsqueeze(0).to(device)\n",
    "        img_for_dino = F.interpolate(img_for_dino, size=(224, 224), mode=\"bilinear\", align_corners=False) \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_emb = self.dino_model.forward_features(img_for_dino).cpu().numpy().astype('float32')\n",
    "            test_emb = test_emb[:, 0, :]  # CLS token only\n",
    "    \n",
    "        # Step 2: Find k nearest neighbors in FAISS (Region of Competence)\n",
    "        distances, neighbors = self.index.search(test_emb, k)\n",
    "        neighbor_idxs = neighbors[0]\n",
    "        local_labels = self.dsel_labels[neighbor_idxs]\n",
    "        local_labels = np.array(local_labels).flatten()\n",
    "    \n",
    "        # Step 3: Get RoC images\n",
    "        with torch.no_grad():\n",
    "            roc_imgs = torch.stack([self.dsel_dataset[idx][0] for idx in neighbor_idxs]).to(device)\n",
    "    \n",
    "        # Step 4: Evaluate classifiers — compute competence and feature similarity\n",
    "        competences, soft_outputs, feature_similarities, passed_fire, correct_counts = [], [], [], [], []\n",
    "    \n",
    "        test_img_batch = test_img.unsqueeze(0).to(device)\n",
    "    \n",
    "        for clf in self.pool:\n",
    "            clf.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = clf(roc_imgs)\n",
    "                preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "                correct = (preds == local_labels).sum()\n",
    "                competence = correct / k\n",
    "                competences.append(competence)\n",
    "                correct_counts.append(correct)\n",
    "\n",
    "                # 🔥 FIRE check: at least one correct per class\n",
    "                fire_ok = fire_check(local_labels, preds, per_class_min=per_class_min) \n",
    "                passed_fire.append(fire_ok)\n",
    "\n",
    "                logits = clf(test_img.unsqueeze(0).to(device)).squeeze(0)\n",
    "                probs = softmax(logits, dim=0)\n",
    "                soft_outputs.append(probs)\n",
    "\n",
    "                # Feature similarity using ResNet embeddings\n",
    "                test_feat = get_features_before_last_linear(clf, test_img.unsqueeze(0).to(device))\n",
    "                roc_feats = get_features_before_last_linear(clf, roc_imgs)\n",
    "                mean_feat = roc_feats.mean(dim=0, keepdim=True)\n",
    "\n",
    "                sim = cosine_similarity(test_feat / test_feat.norm(), mean_feat / mean_feat.norm(), dim=1)\n",
    "                feature_similarities.append(sim.item())\n",
    "\n",
    "        # 5️⃣ KNORA-E selection logic\n",
    "        if knorae: \n",
    "            selected_indices = []\n",
    "            required_correct = k  # start with strict condition (all correct)\n",
    "            while required_correct >= 1 and not selected_indices:\n",
    "                selected_indices = [i for i, c in enumerate(correct_counts) if c >= required_correct]\n",
    "                required_correct -= 1\n",
    "    \n",
    "            if not selected_indices:  # failsafe: fall back to all models\n",
    "                selected_indices = list(range(len(self.pool)))\n",
    "\n",
    "            for i in range(len(self.pool)): \n",
    "                if i not in selected_indices: \n",
    "                    competences[i] = 0.0 \n",
    "                    # feature_similarities[i] = 0.0 \n",
    "    \n",
    "        # Step 5: Combine competence & feature similarity into a score\n",
    "        if use_sim:\n",
    "            selected_feature_sims = [s if s > sim_threshold else 0.0 for s in feature_similarities]\n",
    "            combined_scores = [alpha * c + (1 - alpha) * s for c, s in zip(competences, selected_feature_sims)]\n",
    "        else:\n",
    "            combined_scores = competences[:]\n",
    "        \n",
    "        if use_fire:\n",
    "            combined_scores = [s if passed_fire[i] else 0.0 for i, s in enumerate(combined_scores)]\n",
    "        \n",
    "        # Step 6: Select models\n",
    "        if top:\n",
    "            top_n_idx = np.argsort(combined_scores)[::-1][:n]  # top-n in descending order\n",
    "            total_score = sum(combined_scores[i] for i in top_n_idx)\n",
    "            if total_score == 0:\n",
    "                weights = [1.0 / n] * n\n",
    "            else:\n",
    "                weights = [combined_scores[i] / total_score for i in top_n_idx]\n",
    "        else:\n",
    "            total_score = sum(combined_scores)\n",
    "            if total_score == 0:\n",
    "                weights = [1.0 / len(self.pool)] * len(self.pool)\n",
    "            else:\n",
    "                weights = [s / total_score for s in combined_scores]\n",
    "    \n",
    "        # Step 7: Weighted aggregation of top-n classifier outputs\n",
    "        num_classes = 10\n",
    "        weighted_logits = torch.zeros(10).to(device)\n",
    "\n",
    "        if top: \n",
    "            for idx, weight in zip(top_n_idx, weights):\n",
    "                # print(idx, weight, soft_outputs[idx][:10])\n",
    "                weighted_logits += weight * soft_outputs[idx]\n",
    "        else: \n",
    "            for prob, weight in zip(soft_outputs, weights):\n",
    "                weighted_logits += weight * prob\n",
    "            \n",
    "    \n",
    "        # Step 8: Keep track of suspected attacked model\n",
    "        min_sim_idx = int(np.argmin(feature_similarities))\n",
    "        self.suspected_model_votes.append(min_sim_idx)\n",
    "\n",
    "        # Step 8: Optional explainability\n",
    "        # Step 8: Optional explainability\n",
    "        if explain:\n",
    "            print(\"\\nExplainability Report:\")\n",
    "        \n",
    "            if top:  # only report top-n models\n",
    "                for idx, weight in zip(top_n_idx, weights):\n",
    "                    prob = soft_outputs[idx]\n",
    "                    comp = competences[idx]\n",
    "                    sim = feature_similarities[idx]\n",
    "                    fire = passed_fire[idx]\n",
    "                    com_score = combined_scores[idx]\n",
    "        \n",
    "                    pred_class = prob.argmax().item()\n",
    "                    conf = prob[pred_class].item()\n",
    "                    topk = torch.topk(prob, k=5)\n",
    "        \n",
    "                    print(f\"Model #{idx}: {self.pool[idx].__class__.__name__}\")\n",
    "                    print(f\"  - Competence: {comp:.4f}\")\n",
    "                    print(f\"  - Feature similarity: {sim:.4f}\")\n",
    "                    print(f\"  - Combined score: {com_score:.4f}\")\n",
    "                    print(f\"  - Combined weight: {weight:.4f}\")\n",
    "                    print(f\"  - 🔥 FIRE: {fire}\")\n",
    "                    print(f\"  - Predicted class: {pred_class} with confidence {conf:.4f}\")\n",
    "                    print(f\"  - Top-5: {topk.indices.tolist()} → {[round(p.item(), 3) for p in topk.values]}\")\n",
    "                    print(\"-\" * 50)\n",
    "            else:  # report all models\n",
    "                for idx, (comp, sim, weight, prob, fire, com_score) in enumerate(\n",
    "                    zip(competences, feature_similarities, weights, soft_outputs, passed_fire, combined_scores)\n",
    "                ):\n",
    "                    pred_class = prob.argmax().item()\n",
    "                    conf = prob[pred_class].item()\n",
    "                    topk = torch.topk(prob, k=5)\n",
    "        \n",
    "                    print(f\"Model #{idx}: {self.pool[idx].__class__.__name__}\")\n",
    "                    print(f\"  - Competence: {comp:.4f}\")\n",
    "                    print(f\"  - Feature similarity: {sim:.4f}\")\n",
    "                    print(f\"  - Combined score: {com_score:.4f}\")\n",
    "                    print(f\"  - Combined weight: {weight:.4f}\")\n",
    "                    print(f\"  - 🔥 FIRE: {fire}\")\n",
    "                    print(f\"  - Predicted class: {pred_class} with confidence {conf:.4f}\")\n",
    "                    print(f\"  - Top-5: {topk.indices.tolist()} → {[round(p.item(), 3) for p in topk.values]}\")\n",
    "                    print(\"-\" * 50)\n",
    "        \n",
    "            print(f\"\\n🧠 Final prediction: {weighted_logits.argmax().item()}\")\n",
    "            top5 = torch.topk(weighted_logits, k=5)\n",
    "            print(f\"🔝 Top-5 predictions:\")\n",
    "            for i in range(5):\n",
    "                print(f\"  - Class {top5.indices[i].item()}: {top5.values[i].item():.4f}\")\n",
    "        \n",
    "            print(\"\\nModel weight distribution:\")\n",
    "            if top:\n",
    "                for idx, w in zip(top_n_idx, weights):\n",
    "                    print(f\"  Model #{idx}: {w:.4f}\")\n",
    "            else:\n",
    "                for idx, w in enumerate(weights):\n",
    "                    print(f\"  Model #{idx}: {w:.4f}\")\n",
    "        \n",
    "            print(f\"Suspected attacked model: Model #{min_sim_idx} ({self.pool[min_sim_idx].__class__.__name__})\")\n",
    "        \n",
    "            print(\"\\nRoC visualization:\")\n",
    "            visualize_test_and_roc(test_img.squeeze(0), roc_imgs, local_labels)\n",
    "            print(distances)\n",
    "\n",
    "        if return_logits:\n",
    "            return weighted_logits\n",
    "        return weighted_logits.argmax().item()\n",
    "\n",
    "    def predict(self, dataloader): \n",
    "        total = 0\n",
    "        correct = 0 \n",
    "\n",
    "        dataset_offset = 0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a64e9-ebd9-4f20-aca8-5e2d28b5b20f",
   "metadata": {},
   "source": [
    "### Evaluate DES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5342509-3e95-4f8d-826a-ecdce7bbb17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def evaluate_des_with_fails(des_model, dataloader, dataset, average=\"weighted\"):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    failed_indices = []\n",
    "    dataset_offset = 0  # to map dataloader batches back to dataset indices\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(dataloader, desc=\"Testing VisionDES\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            preds = []\n",
    "            for idx_in_batch, img in enumerate(imgs):\n",
    "                pred = des_model.predict_weighted_robust(\n",
    "                    img, k=5, return_logits=False, explain=False, top=False, n=3, \n",
    "                    use_fire=False, per_class_min=1, use_sim=True, sim_threshold=0, \n",
    "                    alpha=0.6, knorae=True\n",
    "                )\n",
    "                preds.append(pred)\n",
    "\n",
    "                # Collect failures (map batch index to dataset index)\n",
    "                if pred != labels[idx_in_batch].item():\n",
    "                    failed_indices.append(dataset_offset + idx_in_batch)\n",
    "\n",
    "            preds = torch.tensor(preds).to(device)\n",
    "\n",
    "            # accumulate results\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            dataset_offset += labels.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=average, zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Accuracy: {acc*100:.2f} | Precision: {precision*100:.2f} | Recall: {recall*100:.2f} | F1: {f1*100:.2f}\")\n",
    "    \n",
    "    return failed_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b7e6e6-0d75-4bf8-be42-7962574f15d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 250/250 [00:22<00:00, 11.01it/s]\n"
     ]
    }
   ],
   "source": [
    "des_model = VisionDES(val_set, trained_pool)\n",
    "des_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c400e0-5024-4861-9fd8-35942daec86b",
   "metadata": {},
   "source": [
    "## Static Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d7f9a0f-2fc3-4790-ae2d-31eaf5b9c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftVotingEnsemble:\n",
    "    def __init__(self, models, device='cpu'):\n",
    "        self.models = models\n",
    "        self.device = device\n",
    "        for model in self.models:\n",
    "            model.eval().to(device)\n",
    "\n",
    "    def predict(self, images, return_probs=False):\n",
    "        probs = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                outputs = model(images.to(self.device))\n",
    "                softmaxed = torch.softmax(outputs, dim=1)\n",
    "                probs.append(softmaxed.cpu().numpy())\n",
    "        mean_probs = np.mean(np.stack(probs), axis=0)\n",
    "        if return_probs:\n",
    "            return mean_probs\n",
    "        return np.argmax(mean_probs, axis=1)\n",
    "\n",
    "    def predict_single_with_probs(self, image):\n",
    "        image = image.unsqueeze(0)  # Shape [1, C, H, W]\n",
    "        with torch.no_grad():\n",
    "            model_probs = []\n",
    "            for model in self.models:\n",
    "                logits = model(image.to(self.device))\n",
    "                softmaxed = torch.softmax(logits, dim=1)\n",
    "                model_probs.append(softmaxed.cpu().numpy())\n",
    "            mean_probs = np.mean(np.stack(model_probs), axis=0)\n",
    "            probs = mean_probs[0]\n",
    "            pred = np.argmax(probs)\n",
    "            return probs, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a525a59-e8e2-452f-a258-0881a45dccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class HardVotingEnsemble:\n",
    "    def __init__(self, models, device='cpu'):\n",
    "        self.models = models\n",
    "        self.device = device\n",
    "        for model in self.models:\n",
    "            model.eval().to(device)\n",
    "\n",
    "    def predict(self, images):\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                outputs = model(images.to(self.device))\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "        # shape: [n_models, batch_size] → transpose to [batch_size, n_models]\n",
    "        all_preds = np.stack(all_preds, axis=0).T  \n",
    "\n",
    "        # majority vote for each sample\n",
    "        final_preds = []\n",
    "        for preds in all_preds:\n",
    "            most_common = Counter(preds).most_common(1)[0][0]\n",
    "            final_preds.append(most_common)\n",
    "\n",
    "        return np.array(final_preds)\n",
    "\n",
    "    def predict_single_with_probs(self, image):\n",
    "        image = image.unsqueeze(0)  # Shape [1, C, H, W]\n",
    "        votes = []\n",
    "        with torch.no_grad():\n",
    "            for model in self.models:\n",
    "                logits = model(image.to(self.device))\n",
    "                pred = torch.argmax(logits, dim=1).item()\n",
    "                votes.append(pred)\n",
    "\n",
    "        # majority voting\n",
    "        final_pred = Counter(votes).most_common(1)[0][0]\n",
    "        return votes, final_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c50d41e-8678-44e5-bd90-23606f89e3a1",
   "metadata": {},
   "source": [
    "### Attack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a96120b5-a431-4d3f-94bd-fda99aed5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def predict_for_ensembles(ensemble_model, test_loader, ens_type): \n",
    "    metrics = {\n",
    "        'accuracy': [],\n",
    "        'f1': [],\n",
    "        'auc': []\n",
    "    } \n",
    "    y_true, y_pred, y_prob = [], [], [] \n",
    "\n",
    "    for imgs, labels in tqdm(test_loader):\n",
    "        img = imgs[0]\n",
    "        label = labels.item()\n",
    "\n",
    "        if ens_type == \"soft\": \n",
    "            probs, pred = ensemble_model.predict_single_with_probs(img)\n",
    "        if ens_type == \"des+\": \n",
    "            logits = ensemble_model.predict_weighted_robust(\n",
    "                    img, k=10, return_logits=True, explain=False, top=True, n=3, \n",
    "                    use_fire=False, per_class_min=1, use_sim=True, sim_threshold=0.4, \n",
    "                    alpha=0.5, knorae=False\n",
    "                )\n",
    "            probs = torch.softmax(logits, dim=0).cpu().numpy()\n",
    "            pred = np.argmax(probs)\n",
    "    \n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "        y_prob.append(probs)\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_true, y_pred) * 100\n",
    "    f1 = f1_score(y_true, y_pred, average='macro') * 100\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob, multi_class='ovr') * 100\n",
    "    except:\n",
    "        auc = float('nan')\n",
    "\n",
    "    print(f\"{ens_type} Accuracy: {acc:.2f}%  | F1: {f1:.2f}%  | AUC: {auc:.2f}%\")\n",
    "\n",
    "    metrics['accuracy'].append(acc)\n",
    "    metrics['f1'].append(f1)\n",
    "    metrics['auc'].append(auc) \n",
    "    # print(y_prob)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "681daa41-7763-4249-a161-d295fd5c1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifiers(pool, test_dataset, n_classes):\n",
    "    loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    results = []\n",
    "\n",
    "    for i, model in enumerate(pool):\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        y_true, y_pred, y_prob = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs, labels = imgs.to(device), labels.squeeze().long().to(device)\n",
    "                outputs = model(imgs)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "                y_prob.extend(probs.cpu().numpy())\n",
    "\n",
    "        acc = (np.array(y_true) == np.array(y_pred)).mean() * 100\n",
    "        f1 = f1_score(y_true, y_pred, average='macro') * 100\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_prob, multi_class='ovr') * 100\n",
    "        except ValueError:\n",
    "            auc = float('nan')  # Handle single-class test sets\n",
    "\n",
    "        print(f\"{model.__class__.__name__}: {acc}\")\n",
    "\n",
    "        results.append({\n",
    "            'classifier': model.__class__.__name__,\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'auc': auc,\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7440c0f7-8d9f-4e45-8c67-3d31d4540db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_ensemble = SoftVotingEnsemble(trained_pool, device)\n",
    "hard_ensemble = HardVotingEnsemble(trained_pool, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eae08ad-a410-4c23-b14f-9a4d02ba86cf",
   "metadata": {},
   "source": [
    "### Multi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50135ce3-7d7b-468b-a724-378d8a391fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "    \n",
    "for img, label in test_set:\n",
    "    x_test.append(img.numpy())  # if you want channels_last (HWC)\n",
    "    y_test.append(label)\n",
    "        \n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19275ee4-c02f-4385-a8c4-05e685e034b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "410bb238-ce54-458c-986e-2fc9ceee4ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b480d4de45e44eba8ac447082bbd4e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from art.estimators.classification import EnsembleClassifier\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.attacks.evasion import MomentumIterativeMethod \n",
    "from art.attacks.evasion import CarliniL2Method\n",
    " \n",
    "\n",
    "selected_pool_indices = [4] \n",
    "# Wrap your pool into ART classifiers\n",
    "art_classifiers = []\n",
    "for idx in selected_pool_indices:\n",
    "    model = trained_pool[idx].to(device).eval()\n",
    "    dummy_optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    art_clf = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=loss_fn,\n",
    "        optimizer=dummy_optimizer,\n",
    "        input_shape=(3, 32, 32),  # <-- channels_first shape\n",
    "        nb_classes=10,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        channels_first=True,        # <-- make it explicit\n",
    "    )\n",
    "    art_classifiers.append(art_clf)\n",
    "\n",
    "# Create ensemble wrapper\n",
    "ensemble_clf = EnsembleClassifier(classifiers=art_classifiers, channels_first=True )\n",
    "\n",
    "# Run PGD on the whole ensemble\n",
    "# pgd_attack = ProjectedGradientDescent(estimator=ensemble_clf, eps=EPSILON, eps_step=0.01, max_iter=100)\n",
    "# mim = MomentumIterativeMethod(estimator=ensemble_clf, eps=EPSILON, eps_step=0.01, max_iter=100, decay=1.0, \n",
    "#                                targeted=False, batch_size=32, verbose=True) \n",
    "\n",
    "\n",
    "cw = CarliniL2Method(\n",
    "    classifier=ensemble_clf,\n",
    "    confidence=0.0,\n",
    "    targeted=False,\n",
    "    learning_rate=0.01,\n",
    "    max_iter=2,     # C&W often needs many iterations\n",
    "    batch_size=1,\n",
    "    initial_const=1e-3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "    \n",
    "# x_test_adv = pgd_attack.generate(x=x_test)\n",
    "# x_test_adv = mim.generate(x=x_test)\n",
    "x_test_adv = cw.generate(x=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cda2e0a-5d36-4997-8cb0-0316b8c3dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_tensor = torch.tensor(x_test_adv).float()\n",
    "labels_tensor = torch.tensor(y_test).long()\n",
    "adv_dataset = TensorDataset(adv_tensor, labels_tensor)\n",
    "\n",
    "adv_test_loader = DataLoader(adv_dataset, batch_size=1, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df627e76-d71d-4ca8-9673-d2aa3bf8f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet: 91.2\n",
      "DenseNet: 90.55\n",
      "MobileNetV2: 89.4\n",
      "GoogLeNet: 90.5\n",
      "Xception: 53.05\n",
      "InceptionV3: 91.5\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_classifiers(trained_pool, adv_dataset, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aa786cd-b31d-4c66-839b-7014aaf8765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [02:05<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft Accuracy: 93.00%  | F1: 93.03%  | AUC: 99.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [02:05<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft Accuracy: 92.20%  | F1: 92.23%  | AUC: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [08:19<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "des+ Accuracy: 94.25%  | F1: 94.26%  | AUC: 99.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': [94.25],\n",
       " 'f1': [94.26045614911759],\n",
       " 'auc': [np.float64(99.68895040405584)]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_for_ensembles(soft_ensemble, adv_test_loader, \"soft\")\n",
    "predict_for_ensembles(hard_ensemble, adv_test_loader, \"soft\")\n",
    "predict_for_ensembles(des_model, adv_test_loader, \"des+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db95e1b-43c5-4d0e-80a8-e927f1d923dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "des_model.predict_weighted_robust(\n",
    "                    adv_dataset[222][0], k=7, return_logits=False, explain=True, top=False, n=3, \n",
    "                    use_fire=False, per_class_min=1, use_sim=True, sim_threshold=0.5, \n",
    "                    alpha=0.4, knorae=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2827a7c9-6037-4827-a632-1777c739071e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "171eb794-6c82-41d1-aba6-c849c4850b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed73d1721a44f90b9d4b65d4d3bafd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_2:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from art.estimators.classification import EnsembleClassifier\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "selected_pool_indices = [1, 2, 3, 4, 5, 0] \n",
    "# Wrap your pool into ART classifiers\n",
    "art_classifiers = []\n",
    "for idx in selected_pool_indices:\n",
    "    model = trained_pool[idx].to(device).eval()\n",
    "    dummy_optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    art_clf = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=loss_fn,\n",
    "        optimizer=dummy_optimizer,\n",
    "        input_shape=(3, 32, 32),  # <-- channels_first shape\n",
    "        nb_classes=10,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        channels_first=True,        # <-- make it explicit\n",
    "    )\n",
    "    art_classifiers.append(art_clf)\n",
    "\n",
    "# Create ensemble wrapper\n",
    "ensemble_clf = EnsembleClassifier(classifiers=art_classifiers, channels_first=True )\n",
    "\n",
    "# Run PGD on the whole ensemble\n",
    "# pgd_attack = ProjectedGradientDescent(estimator=ensemble_clf, eps=EPSILON, eps_step=0.01, max_iter=100)\n",
    "# mim = MomentumIterativeMethod(estimator=ensemble_clf, eps=EPSILON, eps_step=0.01, max_iter=100, decay=1.0, \n",
    "#                                targeted=False, batch_size=32, verbose=True) \n",
    "\n",
    "\n",
    "cw = CarliniL2Method(\n",
    "    classifier=ensemble_clf,\n",
    "    confidence=0.0,\n",
    "    targeted=False,\n",
    "    learning_rate=0.01,\n",
    "    max_iter=2,     # C&W often needs many iterations\n",
    "    batch_size=1,\n",
    "    initial_const=1e-3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# x_test_adv_1 = pgd_attack.generate(x=x_test)\n",
    "x_test_adv_1 = cw.generate(x=x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4aa95730-fe5c-4017-934f-568ec3f53695",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_tensor_1 = torch.tensor(x_test_adv_1).float()\n",
    "labels_tensor = torch.tensor(y_test).long()\n",
    "adv_dataset_1 = TensorDataset(adv_tensor_1, labels_tensor)\n",
    "\n",
    "adv_test_loader_1 = DataLoader(adv_dataset_1, batch_size=1, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bad3ea87-3f9d-40f2-9a07-011c98d5eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet: 64.75\n",
      "DenseNet: 65.3\n",
      "MobileNetV2: 65.5\n",
      "GoogLeNet: 67.9\n",
      "Xception: 75.7\n",
      "InceptionV3: 73.5\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_classifiers(trained_pool, adv_dataset_1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3654c1ee-e739-479f-8a21-498363147571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [02:04<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft Accuracy: 59.00%  | F1: 59.53%  | AUC: 97.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [01:43<00:00, 19.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft Accuracy: 61.90%  | F1: 62.39%  | AUC: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [08:27<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "des+ Accuracy: 81.55%  | F1: 81.61%  | AUC: 98.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': [81.55],\n",
       " 'f1': [81.60772562025062],\n",
       " 'auc': [np.float64(98.06775469042755)]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_for_ensembles(soft_ensemble, adv_test_loader_1, \"soft\")\n",
    "predict_for_ensembles(hard_ensemble, adv_test_loader_1, \"soft\")\n",
    "predict_for_ensembles(des_model, adv_test_loader_1, \"des+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadd19e-7c9c-48ea-a606-e7a2275566c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from art.estimators.classification import EnsembleClassifier\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "selected_pool_indices = [2, 4, 5] \n",
    "# Wrap your pool into ART classifiers\n",
    "art_classifiers = []\n",
    "for idx in selected_pool_indices:\n",
    "    model = trained_pool[idx].to(device).eval()\n",
    "    dummy_optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    art_clf = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=loss_fn,\n",
    "        optimizer=dummy_optimizer,\n",
    "        input_shape=(3, 32, 32),  # <-- channels_first shape\n",
    "        nb_classes=10,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        channels_first=True,        # <-- make it explicit\n",
    "    )\n",
    "    art_classifiers.append(art_clf)\n",
    "\n",
    "# Create ensemble wrapper\n",
    "ensemble_clf = EnsembleClassifier(classifiers=art_classifiers, channels_first=True )\n",
    "\n",
    "# Run PGD on the whole ensemble\n",
    "# pgd_attack = ProjectedGradientDescent(estimator=ensemble_clf, eps=EPSILON, eps_step=0.01, max_iter=100)\n",
    "\n",
    "mim = MomentumIterativeMethod(estimator=ensemble_clf, eps=EPSILON, eps_step=0.01, max_iter=100, decay=1.0, \n",
    "                               targeted=False, batch_size=32, verbose=True)  \n",
    "\n",
    "# x_test_adv_2 = pgd_attack.generate(x=x_test)\n",
    "x_test_adv_2 = mim.generate(x=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febd99d-f234-4d27-9d7e-92035d4fda3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_tensor_2 = torch.tensor(x_test_adv_2).float()\n",
    "labels_tensor = torch.tensor(y_test).long()\n",
    "adv_dataset_2 = TensorDataset(adv_tensor_2, labels_tensor)\n",
    "\n",
    "adv_test_loader_2 = DataLoader(adv_dataset_2, batch_size=1, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d71194-395f-448d-be89-77a694fe6b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_classifiers(trained_pool, adv_dataset_2, 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38474e9a-c736-4dbc-bd3d-414fc4985417",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_for_ensembles(soft_ensemble, adv_test_loader_2, \"soft\")\n",
    "predict_for_ensembles(hard_ensemble, adv_test_loader_2, \"soft\")\n",
    "predict_for_ensembles(des_model, adv_test_loader_2, \"des+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f48cef-f81b-425c-8e6d-cf7c7e859408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from art.estimators.classification import EnsembleClassifier\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "selected_pool_indices = [1, 2, 4, 5] \n",
    "# Wrap your pool into ART classifiers\n",
    "art_classifiers = []\n",
    "for idx in selected_pool_indices:\n",
    "    model = trained_pool[idx].to(device).eval()\n",
    "    dummy_optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    art_clf = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=loss_fn,\n",
    "        optimizer=dummy_optimizer,\n",
    "        input_shape=(3, 32, 32),  # <-- channels_first shape\n",
    "        nb_classes=10,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        channels_first=True,        # <-- make it explicit\n",
    "    )\n",
    "    art_classifiers.append(art_clf)\n",
    "\n",
    "# Create ensemble wrapper\n",
    "ensemble_clf = EnsembleClassifier(classifiers=art_classifiers, channels_first=True )\n",
    "\n",
    "# Run PGD on the whole ensemble\n",
    "# pgd_attack = ProjectedGradientDescent(estimator=ensemble_clf, eps=EPSILON, eps_step=0.01, max_iter=100)\n",
    "mim = MomentumIterativeMethod(estimator=ensemble_clf, eps=EPSILON, eps_step=0.01, max_iter=100, decay=1.0, \n",
    "                               targeted=False, batch_size=32, verbose=True)   \n",
    "\n",
    "# x_test_adv_3 = pgd_attack.generate(x=x_test)\n",
    "x_test_adv_3 = mim.generate(x=x_test)\n",
    "\n",
    "\n",
    "adv_tensor_3 = torch.tensor(x_test_adv_3).float()\n",
    "labels_tensor = torch.tensor(y_test).long()\n",
    "adv_dataset_3 = TensorDataset(adv_tensor_3, labels_tensor)\n",
    "\n",
    "adv_test_loader_3 = DataLoader(adv_dataset_3, batch_size=1, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd0f90-67af-4e4c-ae9b-647b6906be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_for_ensembles(soft_ensemble, adv_test_loader_3, \"soft\")\n",
    "predict_for_ensembles(hard_ensemble, adv_test_loader_3, \"soft\")\n",
    "predict_for_ensembles(des_model, adv_test_loader_3, \"des+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58a44e-956e-4149-9ef0-66ce6008a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluate_classifiers(trained_pool, adv_dataset_3, 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38efa09b-5be4-4426-9b9d-b82fdb4593dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from art.estimators.classification import EnsembleClassifier\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "selected_pool_indices = [1, 2, 3, 4, 5] \n",
    "# Wrap your pool into ART classifiers\n",
    "art_classifiers = []\n",
    "for idx in selected_pool_indices:\n",
    "    model = trained_pool[idx].to(device).eval()\n",
    "    dummy_optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    art_clf = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=loss_fn,\n",
    "        optimizer=dummy_optimizer,\n",
    "        input_shape=(3, 32, 32),  # <-- channels_first shape\n",
    "        nb_classes=10,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        channels_first=True,        # <-- make it explicit\n",
    "    )\n",
    "    art_classifiers.append(art_clf)\n",
    "\n",
    "# Create ensemble wrapper\n",
    "ensemble_clf = EnsembleClassifier(classifiers=art_classifiers, channels_first=True )\n",
    "\n",
    "# Run PGD on the whole ensemble\n",
    "pgd_attack = ProjectedGradientDescent(estimator=ensemble_clf, eps=EPSILON, eps_step=0.01, max_iter=100)\n",
    "x_test_adv_4 = pgd_attack.generate(x=x_test)\n",
    "\n",
    "\n",
    "adv_tensor_4 = torch.tensor(x_test_adv_4).float()\n",
    "labels_tensor = torch.tensor(y_test).long()\n",
    "adv_dataset_4 = TensorDataset(adv_tensor_4, labels_tensor)\n",
    "\n",
    "adv_test_loader_4 = DataLoader(adv_dataset_4, batch_size=1, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "10f3ec5d-f792-4c01-849b-f8fc29375b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet: 80.80000000000001\n",
      "DenseNet: 70.45\n",
      "MobileNetV2: 59.8\n",
      "GoogLeNet: 56.15\n",
      "Xception: 73.3\n",
      "InceptionV3: 76.6\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_classifiers(trained_pool, adv_dataset_4, 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3f61bc7-7710-4379-8cc1-f7f103ee53ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [01:39<00:00, 20.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft Accuracy: 75.55%  | F1: 75.70%  | AUC: 95.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [01:28<00:00, 22.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft Accuracy: 76.55%  | F1: 76.67%  | AUC: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [06:34<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "des+ Accuracy: 82.10%  | F1: 82.16%  | AUC: 96.17%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': [82.1],\n",
       " 'f1': [82.1568676873148],\n",
       " 'auc': [np.float64(96.17302650251567)]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_for_ensembles(soft_ensemble, adv_test_loader_4, \"soft\")\n",
    "predict_for_ensembles(hard_ensemble, adv_test_loader_4, \"soft\")\n",
    "predict_for_ensembles(des_model, adv_test_loader_4, \"des+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11ad8d7b-8488-412e-bc8b-7f6700ce7561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22fa27b5af247eab8727acbd98debf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b9bd0aff744dd6aa064ff9add06e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddeff5fa67654ba9a7ad133a3441053d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4702dc9bc2844d4a1b8e902f2978265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd59fd9d6bd94bbf94a67f9a667bdaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2266855ce2354d5b9a144a654fc27c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2990814785e747388a0126d68df4af31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8538c330820144488aa99f908cade8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68057c99bf4d44a4804f91d9f949e76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439c8dc6557f4c4aab499bfb826e57f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231ef97553a84a639e65965e85fcdbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74757a2cefbf42cea68d94c1bd2a0748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b107f4795748ec80990e2ee17f7dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc103381ea24990b0fb0289fb3e21f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059a1e259c4b4a289e3136548f9aedc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e130ece3957447bcac4ab07e1655e27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32028bf30c844086a51d0f9ff958ad9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390292b2b02d4af99154e271547071fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c3383afada4a19ae465745dbe8ca17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72167c176bd248b4a3c882569c80cf63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1524829a647433fb25380358f4aa7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb8e1ada8d84b9f9c2279c622bb3675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd26fd8583c44f0683defd2e11b0030d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4230c4b103540a3be80ae8b68bd6818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8aebb0c5d824ba8944bee2b444fa09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60fad8e72564f1596124dd362f488cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2e7027a15648d0a89d0dff8cb7a1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24278726eea46b7a74db4edaa241e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949d11bd6963400181a9b9b1405ef82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e52b7252de464b9a6b05e72292d02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb6b874209748c3ae0a62f7284806cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fcf9d8df4b4f5eb6268703e5716eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4986f3433104485a0e162fd2e04e125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e53d212b790477aa722ed7dc9efc61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4537728fc9bc4333823d7e1dc6c2bbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96613f09011c4ffc8724a1ee1482a842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d48516bea37474f9601e7179d09ad81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9334a4cb58894e0ba133623aec334e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ec581d0e804bdbb66d55a3a11812a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bef29767b6649d5ace8e7196a12424e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23053c44faf8411ab7feb431da69761c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1decbd1f4f84e7b941b162a8f32c5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff5a0c129a24fb1b72e103c92f04fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab69f66e224d4851b98dcede81e51d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd4ce5106b243d393aa3f99159d485a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181c8956e39c4f0f8b2224f7e0cd227f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e07fe6f47c452885156277a1b7e35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2ba82cb97b42fa8883fd1895cf0cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe8c2d45ba74412b2a22ff4c502735d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8507e9cfd45344b682603f3fb463de60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4a90a7354c404c83c3607e3d51d62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833d10027db941b585e6be84c984cb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604944e301fe43848e4d405b99e1da8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd48b5875654ffe871d421119d08a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc1d0ab6a4941f8807caac889df21da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ac705a99604412adee4d3a804e9a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e242f9433af94442969a6e5e08887fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc4009d10a7464b92a66ed58c6ada98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f4c9a358e54b7881a5de36b270e1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c830ffab450a4de19e2afccd1f9cc319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f050c0ea4e284970a070466998a84a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b49cca16b4e48cd98c9f0c77e283130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568eef4d59094ad083d839f5417f4ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d6906fbf2b4258899d6e1ede1fcb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d11872a27e42a683c596d002325cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16952d1c60034730b6ca3847f45071eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce6b5e9adf94639b5ea0825352882c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11c9c87cc674ed2a2ad76a2c13897d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826d41d3b45944d3a5662f706a372b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646985d019524d50ba447ada00ec147b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f854f2b7915b44a19dda5da329fd4a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c9ba00c9f04a02a9362c1ef5d3f289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304a821f908c4cc69256c91ea12e8265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85911c5a648413096d59692a0253f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada7f52963d2448fa662b1d27321108b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8942f2f2d9bb41daa0d0315091d46d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62353b4ffe2841e9b0f9278811c26626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423a7ec23bd842c69ac0ba30bd5a91e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13abe2654164ec6bcb7735095de7c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c795d9a5b9534de7a04c569d58830dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1942b8b5bf2347aabb674ca8cdc3dfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bc1da725054bc9bda6e72b8ff09e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70f63de66d74b168d40a9daf4b2733c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9d1c3db86f4cae90b9a9b44d4d4989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e71c79b90c4e318a95bdb8313f82d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7be6173495146c4a3b7b74108196de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58febeb48a334f619e3d5bd0f6380d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1db173cdb647e0ab98f483593b9c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d066752d5af425fb29d5d65759ac16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690e7d506ca048c38cbc6ec1797465e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f80477f7df64fd0883b7e865ad3d5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79981fb478f433dabe432fdc0f4c69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700b61dde1be4947abf933141a6e4e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8104e4b9064b7b9dda3145b2880e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e61723ef524f9291bb2c9a20e735df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a91dc81f5649048b1b61786ccb9c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527f567173824fb4b4b25824f28e93c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2a2728ba164f0ebd020be64e1582b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6ab7666ed547f89a0c760e34917e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47a3a9ae7074949badc074b44aba73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab78eab9790428c89b96ad17f1bec78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa4a615a90c4bc6b1791564b5caa652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b01ccb01134ac79d2948339e60e9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9418bdb2036f49088476979f11ce098c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7049a263ec9a402ab5f8485899ad90ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c16b242b4c4e5db514aa88aca9ba5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e9092500d74609af660e897b957ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b641a2aeea4556997302152d3c313a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fd36535c104d19805436359f4dc04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e57b00b1834933a94ac1d921fa5076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92c97497a8f4327afce86766f4e6574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fc118079ef4c1ca623a33b031e735d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5794ac82865e4ec8840367b231852b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9243cbce694971a32890cf9f325163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0972102ef70b45a9a3d5b82b61373d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe39ef6d6a1846e6b1503c695c0d5052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8a0c81dbac4440a6afbfcd456dc602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409e762bade14bf2a1e39c7a88a3d953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a01cafbe5e41339fc468429cbd5f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a559e7a5989f442594e9a6164273838d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d5346f7da24e3aa565961873e683a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fb8fbeaf0b4ba1912f1ddd91768860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3cfd60d9667440ba02362a1b5b49672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2292c44bdd442d832b7542e2ced39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74619b624973443e8fd360f0b00148a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631d69b5e1964007a3737c7353ef33bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from art.estimators.classification import EnsembleClassifier\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "\n",
    "selected_pool_indices = [0, 1, 2, 3, 4, 5] \n",
    "# Wrap your pool into ART classifiers\n",
    "art_classifiers = []\n",
    "for idx in selected_pool_indices:\n",
    "    model = trained_pool[idx].to(device).eval()\n",
    "    dummy_optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    art_clf = PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=loss_fn,\n",
    "        optimizer=dummy_optimizer,\n",
    "        input_shape=(3, 32, 32),  # <-- channels_first shape\n",
    "        nb_classes=10,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        channels_first=True,        # <-- make it explicit\n",
    "    )\n",
    "    art_classifiers.append(art_clf)\n",
    "\n",
    "# Create ensemble wrapper\n",
    "ensemble_clf = EnsembleClassifier(classifiers=art_classifiers, channels_first=True )\n",
    "\n",
    "# Run PGD on the whole ensemble\n",
    "pgd_attack = ProjectedGradientDescent(estimator=ensemble_clf, eps=EPSILON, eps_step=0.01, max_iter=100)\n",
    "x_test_adv_5 = pgd_attack.generate(x=x_test)\n",
    "\n",
    "\n",
    "adv_tensor_5 = torch.tensor(x_test_adv_5).float()\n",
    "labels_tensor = torch.tensor(y_test).long()\n",
    "adv_dataset_5 = TensorDataset(adv_tensor_5, labels_tensor)\n",
    "\n",
    "adv_test_loader_5 = DataLoader(adv_dataset_5, batch_size=1, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "320bfa38-5ddd-49b8-aed9-82b156cbc6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet: 71.45\n",
      "DenseNet: 69.3\n",
      "MobileNetV2: 59.199999999999996\n",
      "GoogLeNet: 56.89999999999999\n",
      "Xception: 73.95\n",
      "InceptionV3: 75.7\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_classifiers(trained_pool, adv_dataset_5, 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "705216be-2116-4068-9939-ca71f9d3e2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [01:28<00:00, 22.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft Accuracy: 72.95%  | F1: 73.21%  | AUC: 94.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [01:28<00:00, 22.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft Accuracy: 72.85%  | F1: 73.09%  | AUC: nan%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 2000/2000 [06:34<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "des+ Accuracy: 79.85%  | F1: 79.96%  | AUC: 94.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': [79.85],\n",
       " 'f1': [79.96424494348179],\n",
       " 'auc': [np.float64(94.61423389847873)]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_for_ensembles(soft_ensemble, adv_test_loader_5, \"soft\")\n",
    "predict_for_ensembles(hard_ensemble, adv_test_loader_5, \"soft\")\n",
    "predict_for_ensembles(des_model, adv_test_loader_5, \"des+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c171f18-e120-4ca3-a12a-41758b4f7a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
